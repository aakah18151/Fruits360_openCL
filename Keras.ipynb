{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16-sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 50)                204850    \n",
      "=================================================================\n",
      "Total params: 207,618\n",
      "Trainable params: 207,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D\n",
    "\n",
    "input_shape = (32, 32, 3) \n",
    "\n",
    "model = Sequential(name='vgg16-sequential')\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape, name='block1_conv1'))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu', name='block1_conv2'))\n",
    "model.add(MaxPool2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "model.add(Dense(50, activation='softmax', name='predictions'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ece5iai/aakash18151/anaconda3/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ece5iai/aakash18151/anaconda3/lib/python3.7/site-packages (from pydot) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25100 images belonging to 50 classes.\n",
      "Found 8478 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = \"Training_new\"\n",
    "test_path = \"Test_32x32\"\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(32, 32), class_mode=\"categorical\", batch_size=251)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(32, 32), class_mode=\"categorical\", batch_size=157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      " - 25s - loss: 9.0018 - accuracy: 0.4816 - val_loss: 0.9083 - val_accuracy: 0.7876\n",
      "Epoch 2/11\n",
      " - 11s - loss: 0.0552 - accuracy: 0.9871 - val_loss: 0.3702 - val_accuracy: 0.8950\n",
      "Epoch 3/11\n",
      " - 11s - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.3659 - val_accuracy: 0.9173\n",
      "Epoch 4/11\n",
      " - 11s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.4749 - val_accuracy: 0.9213\n",
      "Epoch 5/11\n",
      " - 11s - loss: 6.1083e-04 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9276\n",
      "Epoch 6/11\n",
      " - 11s - loss: 9.8019e-04 - accuracy: 0.9999 - val_loss: 0.4906 - val_accuracy: 0.9246\n",
      "Epoch 7/11\n",
      " - 11s - loss: 4.7414e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9306\n",
      "Epoch 8/11\n",
      " - 11s - loss: 1.5586e-04 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9304\n",
      "Epoch 9/11\n",
      " - 11s - loss: 1.0821e-04 - accuracy: 1.0000 - val_loss: 0.5696 - val_accuracy: 0.9336\n",
      "Epoch 10/11\n",
      " - 11s - loss: 9.0676e-05 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9377\n",
      "Epoch 11/11\n",
      " - 11s - loss: 7.1984e-05 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb084109780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=100,validation_data=test_batches,validation_steps=54,epochs=11,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fb0ba441b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biases :  (50,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Biases : \", model.layers[4].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02455233, -0.01121073, -0.00709064, ..., -0.01361853,\n",
       "         0.03695786, -0.04038417],\n",
       "       [-0.01235719, -0.02359619,  0.01707634, ...,  0.03856889,\n",
       "         0.00445458,  0.03962469],\n",
       "       [ 0.02684362, -0.01365526, -0.00883746, ..., -0.02740848,\n",
       "         0.02116891,  0.04208881],\n",
       "       ...,\n",
       "       [ 0.02313991, -0.06889132, -0.02330975, ..., -0.03010493,\n",
       "        -0.02544045,  0.019929  ],\n",
       "       [-0.02159299, -0.02008313,  0.02679505, ..., -0.00425829,\n",
       "        -0.00907113,  0.01336208],\n",
       "       [ 0.00825535, -0.00033172,  0.01276093, ...,  0.03733187,\n",
       "         0.03966337,  0.02495866]], dtype=float32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[4].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=wt.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features dim :  4096\n",
      "Out Features dim :  50\n"
     ]
    }
   ],
   "source": [
    "inputFeatures = model.layers[4].get_weights()[0].shape[0]\n",
    "outFeatures = model.layers[4].get_weights()[0].shape[1]\n",
    "print(\"Input features dim : \", inputFeatures)\n",
    "print(\"Out Features dim : \", outFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('f.txt',pr,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features dim :  4096\n",
      "Out Features dim :  50\n"
     ]
    }
   ],
   "source": [
    "# Fully connected\n",
    "for fc_layer in [4]:\n",
    "  #fc_layer = 7   # 5,6,7\n",
    "  inputFeatures = model.layers[fc_layer].get_weights()[0].shape[0]\n",
    "  outFeatures = model.layers[fc_layer].get_weights()[0].shape[1]\n",
    "  print(\"Input features dim : \", inputFeatures)\n",
    "  print(\"Out Features dim : \", outFeatures)\n",
    "  fileName = model.layers[fc_layer].name\n",
    "  fileName += \".txt\"\n",
    "  fileHandler = open(fileName, \"w\")\n",
    "  for outFeature in range(0, outFeatures):\n",
    "    for inFeature in range(0, inputFeatures):\n",
    "      fileHandler.write(str(model.layers[fc_layer].get_weights()[0][inFeature][outFeature]) + \" \")\n",
    "  fileHandler.write(\"\\n\")\n",
    "\n",
    "  for bias in range(0, outFeatures):\n",
    "    fileHandler.write(str(model.layers[fc_layer].get_weights()[1][bias]) + \" \")\n",
    "  fileHandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Width :  3\n",
      "Kernel Height :  3\n",
      "Kernel Depth :  3\n",
      "Num Channels :  16\n",
      "Kernel Width :  3\n",
      "Kernel Height :  3\n",
      "Kernel Depth :  16\n",
      "Num Channels :  16\n"
     ]
    }
   ],
   "source": [
    "layer_no = 0 # 2,0\n",
    "for layer_no in [0,1]:\n",
    "  kernelWidth = model.layers[layer_no].get_weights()[0].shape[0]\n",
    "  kernelHeight = model.layers[layer_no].get_weights()[0].shape[1]\n",
    "  kernelDepth = model.layers[layer_no].get_weights()[0].shape[2]\n",
    "  print(\"Kernel Width : \", kernelWidth)\n",
    "  print(\"Kernel Height : \", kernelHeight)\n",
    "  print(\"Kernel Depth : \", kernelDepth)\n",
    "  numChannels = model.layers[layer_no].get_weights()[0].shape[3]\n",
    "  print(\"Num Channels : \", numChannels)\n",
    "  fileName = model.layers[layer_no].name\n",
    "  fileName += \".txt\"\n",
    "  fileHandler = open(fileName, \"w\")\n",
    "  for channels in range(0, numChannels):\n",
    "    for depth in range(kernelDepth):\n",
    "      for width in range(kernelWidth):\n",
    "        for height in range(kernelHeight):\n",
    "          fileHandler.write(str(model.layers[layer_no].get_weights()[0][width, height, depth, channels]) + \" \")\n",
    "  fileHandler.write(\"\\n\")\n",
    "  # Store biases\n",
    "  for channels in range(0, numChannels):\n",
    "    fileHandler.write(str(model.layers[layer_no].get_weights()[1][channels]) + \" \");\n",
    "  fileHandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Permute\n",
    "\n",
    "layer1 = Input(shape=(32, 32, 3))\n",
    "layer2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu',padding='same')(layer1)\n",
    "layer3 = Conv2D(filters=16, kernel_size=(3, 3),padding='same', activation='relu')(layer2)\n",
    "layer4 = MaxPooling2D(pool_size=(2, 2))(layer3)\n",
    "layer5 = Flatten(data_format='channels_first')(layer4)\n",
    "layer6 = Dense(50, activation='linear')(layer5)\n",
    "\n",
    "\n",
    "# modelTrun = Model(inputs=layer1, outputs=layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "modelTrun = Model(inputs=layer1, outputs=layer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1\n",
      "conv2d_2\n",
      "max_pooling2d_1\n",
      "flatten_1\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "modelTrun.layers[1].set_weights(model.layers[0].get_weights())\n",
    "print(modelTrun.layers[1].name)\n",
    "modelTrun.layers[2].set_weights(model.layers[1].get_weights())\n",
    "print(modelTrun.layers[2].name)\n",
    "modelTrun.layers[3].set_weights(model.layers[2].get_weights())\n",
    "print(modelTrun.layers[3].name)\n",
    "modelTrun.layers[4].set_weights(model.layers[3].get_weights())\n",
    "print(modelTrun.layers[4].name)\n",
    "modelTrun.layers[5].set_weights(model.layers[4].get_weights())\n",
    "print(modelTrun.layers[5].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "img2 = imread(\"Test_32x32/Banana/12_100.jpg\")\n",
    "print(type(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[251, 255, 248],\n",
       "        [251, 255, 250],\n",
       "        [252, 255, 251],\n",
       "        ...,\n",
       "        [254, 255, 246],\n",
       "        [255, 255, 253],\n",
       "        [250, 248, 251]],\n",
       "\n",
       "       [[251, 255, 250],\n",
       "        [251, 255, 250],\n",
       "        [252, 255, 251],\n",
       "        ...,\n",
       "        [251, 254, 245],\n",
       "        [252, 252, 250],\n",
       "        [255, 254, 255]],\n",
       "\n",
       "       [[251, 255, 251],\n",
       "        [252, 255, 251],\n",
       "        [252, 255, 253],\n",
       "        ...,\n",
       "        [255, 255, 251],\n",
       "        [250, 248, 249],\n",
       "        [255, 253, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[253, 255, 245],\n",
       "        [253, 255, 245],\n",
       "        [252, 255, 246],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[250, 254, 253],\n",
       "        [250, 254, 253],\n",
       "        [252, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 254, 255],\n",
       "        [255, 254, 255]],\n",
       "\n",
       "       [[251, 254, 255],\n",
       "        [252, 255, 255],\n",
       "        [252, 255, 255],\n",
       "        ...,\n",
       "        [255, 254, 255],\n",
       "        [255, 254, 255],\n",
       "        [255, 254, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reshaped=np.stack((img2[:,:,0],img2[:,:,1], img2[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[251 251 252 ... 254 255 250]\n",
      "  [251 251 252 ... 251 252 255]\n",
      "  [251 252 252 ... 255 250 255]\n",
      "  ...\n",
      "  [253 253 252 ... 255 255 255]\n",
      "  [250 250 252 ... 255 255 255]\n",
      "  [251 252 252 ... 255 255 255]]\n",
      "\n",
      " [[255 255 255 ... 255 255 248]\n",
      "  [255 255 255 ... 254 252 254]\n",
      "  [255 255 255 ... 255 248 253]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [254 254 255 ... 255 254 254]\n",
      "  [254 255 255 ... 254 254 254]]\n",
      "\n",
      " [[248 250 251 ... 246 253 251]\n",
      "  [250 250 251 ... 245 250 255]\n",
      "  [251 251 253 ... 251 249 255]\n",
      "  ...\n",
      "  [245 245 246 ... 255 255 255]\n",
      "  [253 253 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([251, 251, 252, ..., 255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fl = img_reshaped.flatten()\n",
    "img_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([244, 250, 246, ..., 255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rs_fl = img2.flatten()\n",
    "img_rs_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = modelTrun.predict(img2.reshape(1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.07412484,  13.488444  , -30.044628  , -25.289286  ,\n",
       "          1.9167101 , -15.434257  , -18.87718   , -11.921204  ,\n",
       "         -3.9826117 ,   3.5211773 ,  -7.742969  ,   3.2652245 ,\n",
       "        -13.832905  ,  -0.30899525,  -6.493058  , -11.331507  ,\n",
       "         -6.666646  ,   7.3075337 ,  12.901896  , -19.338577  ,\n",
       "         -6.324942  ,  -8.186701  ,  -7.810067  ,   5.4808464 ,\n",
       "          1.5766498 ,  14.2494955 , -26.64786   ,  -9.3373375 ,\n",
       "         12.1898985 , -10.893387  ,   1.9430412 , -11.230575  ,\n",
       "        -20.572903  , -17.844627  ,   8.21945   ,   6.375868  ,\n",
       "         -4.675418  ,   3.3220718 ,   0.73408353, -12.69471   ,\n",
       "         -1.7531934 ,   0.93590397, -15.047206  , -12.389329  ,\n",
       "        -14.8535185 ,   5.3839183 , -12.724849  , -11.156646  ,\n",
       "          4.307355  ,   4.2647862 ]], dtype=float32)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"B.txt\",img_fl,fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
